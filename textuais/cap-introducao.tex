%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% 1 ::: Introdução
\chapter{Introdução}
    Em um ambiente de produção industrial moderna a optimização é um ponto de grande importância, devido à constante mudança e alta concorrência. Em ramos como a manufatura isso se mostra especialmente importante, podendo ser o fator decisório para o sucesso de uma empresa \cite{Wari2016}.\hfill  
    
    Um dos exemplos de otimização em sistemas de manufatura é dentro de um cenário onde existem diversas máquinas independentes e uma fila de tarefas não homogêneas, e o objetivo é achar uma programação de onde cada tarefa será executada e em qual ordem, de maneira a economizar o máximo de tempo e energia.\newline

    Em um ambiente de alta concorrência é importante que essa ordem seja encontrada quanto antes, pois essa demora para encontrar a solução significa perda de tempo de produção. Porém, a busca de um bom escalonamento, ou seja, a configuração e ordem de execução, não é uma tarefa fácil. Pois, o número de possibilidades de arranjos cresce exponencialmente, e computar todas as soluções possíveis torna-se inviável após alguns níveis. \newline

    Por causa dessa característica exponencial conforme o número de máquinas e o número de problemas, esse problema de escalonamento é classificado como um problema de otimização de análise combinatória e pertence à classe de problemas \textit{NP-Hard}. \newline

    Os problemas da classe \textit{NP-Hard} são aqueles onde a resposta não pode ser encontrada computacionalmente em um tempo polinomial, ou seja, em um tempo razoável, porém uma solução pode ser verificada em tempo polinomial \cite{Eswaramurthy2008}.\newline

    Existem diversos problemas clássicos de produção e manufatura enquadrados em problemas de otimização e escalonamento, o que torna esse assunto uma área de muito interesse para pesquisadores do mundo inteiro.\newline

    Dentre os problemas clássicos de escalonamento e planejamento de produção estão: 
    \textit{Single Machine Scheduling Problem}, 
    \textit{Parallel Machine Scheduling Problem}, 
    \textit{Flow Shop Scheduling Problem}, 
    \textit{Job Shop Scheduling Problem} e 
    \textit{Open Shop Scheduling Problem} 
    \cite{Allahverdi2008}.\newline

    Como esses problemas não são possíveis de serem resolvidos em tempo polinomial, não é possível encontrar uma solução perfeita para eles. Mas é possível encontrarmos uma solução boa o suficiente, conforme os critérios de avaliação do problema, essa solução é chamada solução ótima.\newline

    \textit{Job Shop Scheduling Problem} (JSSP) é um do problema pertencente a classe de problemas \textit{NP-Hard}, ele chama muito a atenção de pesquisadores por ser um problema com diversas aplicações no mundo real, seja em ambientes de manufatura ou em planejamento de produção, ou até mesmo em logística \cite{Cheng1996}.\newline

    Nesse problema, temos um conjunto $m$ de máquinas e um conjunto $n$ de tarefas chamadas \textit{jobs}, sendo cada \textit{job} uma sequência de operações, cada uma com seu determinado tempo de execução. \newline 

    O objetivo é encontrar um escalonamento que combine todas as máquinas de forma que minimize a quantidade de tempo ocioso de cada máquina, assim atingindo o objetivo de forma que seja mais econômica e eficiente \cite{Cheng1996}. \newline

    O problema de JSP é comprovadamente pertencente à classe \textit{NP-Hard} quando em um ambiente com duas ou mais máquinas, como demonstrado por \cite{Lenstra1979}. \newline

    Porém, assim como visto por \cite{Bagchi1999} existem algumas restrições no cenário de JSP, dentre elas:
    \begin{itemize}
        \item Duas operações do mesmo \textit{job} não podem ser executadas em simultâneo;
        \item Nenhuma máquina pode executar simultaneamente mais de uma operação;
        \item As restrições e configurações de processamento são conhecidas previamente e não são alteradas;
        \item Todo \textit{job} deve ser processado até o fim, mas é permitido que haja pausas e esperas entre suas operações;
        \item As máquinas são homogêneas;
        \item Nenhum \textit{job} pode ser processado duas vezes na mesma máquina;
        \item As operações são atômicas, não sendo possível interromper ou pausar a execução da mesma;
    \end{itemize}

    O problema de Job Shop Flexível ou \textit{Flexible Job Shop Problem} (FJSP) é uma extensão do JSP onde é possível que uma operação seja executada em mais de uma máquina. Sendo assim deve se além de determinar a ordem e o local de execução de cada \textit{job}, também é preciso determinada ordem e local de execução das operações. Assim sendo considerado uma extensão mais complexa do JSP \cite{Jansen2000}. \newline

    Além disso, o problema de FJSP pode ser dividido em dois tipos, o parcial (P-FJSP), onde uma operação só pode ser executada por um subconjunto de máquinas, ou o total (T-FJSP), onde qualquer operação pode ser executada por qualquer máquina. O FJSP tem as mesmas restrições do JSP exceto a que diz que nenhum \textit{job} pode ser processado duas vezes na mesma máquina. \newline

    Ao longo do tempo já foram propostas diversas abordagens para resolver o problema de FJSP, dentre elas o \textit{Branch and Bound} \cite{Nababan2008}, a 
    \textit{Integer Programming} \cite{Pan2007}, a 
    \textit{Dynamic Programming} \cite{Gromicho2012}, 
    \textit{Evolutionary Algorithm} \cite{Pezzella2008}, e até mesmo técnicas híbridas \cite{Zhang2009}, onde duas ou mais abordagens são associadas para compor um algoritmo híbrido. \newline

    Um desses algoritmos propostos é o algoritmo de Otimização por Enxame de Partículas ou \textit{Particle Swarm Optimization} (PSO) proposto por \cite{Kennedy1995} e trabalha com um grupo de indivíduos cada um tendo: direção, velocidade, a informação da sua melhor posição e a informação da melhor posição entre todos os indivíduos do grupo, e com essas informações cada indivíduo consegue tirar sua média e a cada rodada do algoritmo ir chegando mais perto do objetivo. \newline

    Outra abordagem que tem tido bons resultados em diversos problemas práticos \cite{Qing2012} são os Algoritmos Genéticos ou \textit{Genetic Algorithms} (GA), proposto por \textit{John Henry Holland} sendo inspirado na teoria da evolução de Charles Darwin, simulando a transmissão de genes dos indivíduos mais aptos por meio da simulação de operações de cruzamento e de mutações, para selecionar os indivíduos mais aptos. \newline

    Neste trabalho iremos demonstrar e comparar a eficiência de uma abordagem híbrida do Algoritmo PSO com componentes evolutivos de GA, tornando assim esse algoritmo mais dinâmico, além de demonstrar sua eficiência em diferentes cenários reais de aplicação na indústria.\newline


%% 1 ::: Introdução
%% 1.1
\section{Problemas de Agendamento}
    %% Interlúdio do [Problemas de Agendamento] %%
        Problemas de agendamento estão muito presentes atualmente, e existem diretamente em diversos cenários, tais como planejamento de produção, sistemas de manufatura, sistemas de produção, processamento de informação, gerenciamento de rotas de logísticas, etc. e indiretamente nos computadores através do escalonamento de processos do sistema operacional.\newline

        Com tantos possíveis cenários de aplicação é natural que existam inúmeras sub-divisões deste problema. Porém, a maioria deles tem características em comum. Geralmente eles se baseiam em um conjunto de recursos e um conjunto de demandas, e visa ordenar as execuções das demandas e as distribuir entre os recursos, isso de modo a alcançar da melhor possível um ou mais objetivos, que podem ser, por exemplo, o tempo total para o algoritmo executar o agendamento (também chamado \textit{makespan}), o tempo total de execução de todas as tarefas no agendamento encontrado (também chamado \textit{fitness}) ou a soma total do tempo de ociosidade das máquinas.\newline

        Por essa característica de buscar um melhor resultado em um objetivo os problemas de agendamento são caracterizados como problemas de optimização, que são os problemas que a solução são aquelas que trazem um melhor resultado para o objetivo. É importante ressaltar que nesses problemas de optimização a solução não necessariamente precisa a melhor possível, mas sim uma solução boa o suficiente (também chamado solução ótima).\newline

        Os problemas de agendamento multi-objetivo consideram em simultâneo, mais de um critério de avaliação, podendo ter ou não o mesmo peso, ou nível de importância, e espera se que sejam atingidos todos os objetivos. Por causa dessa diversidade de objetivos que podem muitas vezes serem conflitantes entre si, como, por exemplo, ser mais rápido e, em simultâneo, gastar a menor quantidade possível de energia.\newline

        Já os problemas de agendamento mono-objetivo lidam somente com um critério de avaliação, o que diminui significativamente a dificuldade para encontrar uma solução, porém, em contrapartida, define uma importância maior para o objetivo em questão, sendo necessário um maior nível de refinamento da solução.
    %% Fim do Interlúdio do [Problemas de Agendamento] %%

    %% 1 ::: Introdução
    %% 1.1 ::: Problemas de Agendamento
    %% 1.1.1
    \subsection{Definição}
        Como foi definido por \cite{Bagchi1999} um problema de escalonamento de tarefas computacionais (\textit{jobs}) é um problema de otimização aonde os recursos limitados são alocados no tempo de execução dos recursos, com as diferentes tarefas podendo ser executadas em paralelo entre as diversas maquinas, porém, cada atividade única sendo executada sequenciamento em uma só maquina.\newline

        Assim como a grande maioria dos problemas de origem combinatória, ou seja, que um fator depende o fator anterior, formando assim uma combinação de fatores, o problema de escalonamento é um problema da classe NP-Hard da qual não é possível se encontrar a melhor solução possível em um tempo polinomial, ou seja, computacionalmente aceitável, devido a sua quantidade de operações necessárias crescer exponencialmente, com base no tamanho do problema, tornando se assim um problema inviável de se resolver através de cálculos brutos.\newline

        Por causa disso, nesses casos de problemas NP-Hard normalmente se usam algoritmos de aproximação, que tenham um tempo de execução razoável e consigam encontrar uma solução boa o suficiente com base nos critérios de avaliação, a chamada "Solução Ótima", como visto por \cite{Lawler1993}.\newline

        Porém, esse conceito de solução ótima varia conforme o problema, em alguns casos é mais importante que essa solução seja encontrada em um tempo curto, do que ela seja alguns milissegundos mais rápida do que as outras soluções já encontradas, isso se aplica em ambientes que o agendamento deve ser feito em tempo real.\newline
        Já para um problema em que essa solução precisa ser encontrada apenas uma vez e ser replicada varias vezes, como uma estrutura de linha de montagem definitiva, vale a pena esperar algumas horas a mais se essa solução economizar tempo de produção ao longo do seu uso. Então esse critério de avaliação de solução ótima deve ser muito bem analisado de caso a caso. \newline

        Nesses ambientes de soluções aproximadas, alguns algoritmos que se destacam são os algoritmos bio inspirados, algoritmos populacionais e algoritmos evolutivos. Que conseguem simular uma inteligência biológica ou comportamentos já observados na natureza e selecionados pela evolução para encontrar uma solução ótima, de maneira similar a que um ser vivo faria.
    %% Fim do [Definição] %%


    %% 1 ::: Introdução
    %% 1.1 ::: Problemas de Agendamento
    %% 1.1.2
    \subsection{Variações}
        Diversos autores já classificaram diversas variações de problemas de escalonamento dentre eles \cite{graham1979}, \cite{Lenstra1979}, e \cite{maccarthy1993}. O que diferencia os problemas são o fluxo dos \textit{jobs} a serem processados e a capacidade dos recursos. Dentre esses problemas estão:
        \begin{itemize}
            \item \textbf{\textit{Open Shop:}} Os \textit{job} tem uma ordem de execução, porém as operações de cada \textit{job} tem uma ordem específica de execução.
            
            \item \textbf{\textit{Flow Shop:}} Os \textit{jobs} devem ser executados em um fluxo unidirecional e em uma máquina somente. E não exite uma divisão do \textit{jobs} em operações.
            
            \item \textbf{\textit{Flexible Flow Shop:}} Semelhante ao \textit{Flow Shop}, porém os \textit{jobs} podem ser divididos em operações.
            
            \item \textbf{\textit{Job Shop:}} Diferentemente do \textit{Flow Shop} o \textit{Job Shop} pode ter execuções paralelas, assim como ser dividido em operações.
            
            \item \textbf{\textit{Flexible Job Shop:}} Uma extensão do \textit{Job Shop} onde as operações de cada \textit{Job} podem ser executados em máquinas diferentes. Esse problema tem duas sub divisões, a Total, em que todas as maquinas podem executar todas as operações. E a Parcial, onde existem limitações para quais maquinas podem executar quais operações.
        \end{itemize}

        Além disso, cada um dos problemas acima podem ser sub-classificados como mono-objetivos ou multi-objetivos conforme os tipos e a quantidade de objetivos. \newline
        No caso de ter somente um único objetivo, como um menor \textit{fitness} por exemplo, ou ter mais de um objetivo, como um menor \textit{fitness} e um menor índice de inércia total.\newline

        Esse trabalho é focado no problema de \textit{Flexible Job Shop} Total, em um contexto mono-objetivo.
    %% Fim do [Problema] %%


    %% 1 ::: Introdução
    %% 1.1 ::: Problemas de Agendamento
    %% 1.1.3
    \subsection{Problema de Job Shop — JSP}
        %% Interlúdio do [Problemas de Agendamento] %%
            Como citado anteriormente o \textit{Job Shop Problem} (JSP) é um problema de escalonamento de tarefas e pertence à classe de problemas NP-Hard. Como visto por \cite{Cheng1996} o problema de \textit{Job Shop} chama muita atenção por ser um problema com diversas aplicações no mundo real, e em diversos cenários diferentes, como industria, computação e manufatura.\newline

            De acordo com \cite{Cheng1996} o problema de \textit{Job Shop} consiste em $m$ máquinas distintas e $n$ \textit{jobs} diferentes, sendo cada \textit{job} formado por diversas operações $O$ em uma ordem específica. Cada operação $Oij$ tem seu respectivo tempo de execução.\newline

            Como visto por \cite{Bagchi1999} existem algumas restrições no problema de \textit{Job Shop} dentre elas:
            \begin{itemize}
                \item Mais de uma operação de um mesmo \textit{job} não pode ser executada em simultâneo.
                \item Não existe mais de uma máquina de um mesmo tipo.
                \item As máquinas podem ficar ociosas durante o período de escalonamento.
                \item As execuções de \textit{jobs} são atômicas, ou seja, cada \textit{job} deve ser processado até o fim.
                \item Uma máquina não pode executar mais de uma operação simultaneamente.
                \item Um \textit{job} não é processado duas vezes na mesma máquina.
                \item Não é possível interromper a execução de uma operação.
            \end{itemize}
        %% Fim do Interlúdio do [Problemas de Agendamento] %%
        
        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.3 ::: JSP
        %% 1.1.3.1
        \subsubsection{Representações}
            Para ser possível que um algoritmo encontre uma solução para o agendamento, ele precisar conhecer algumas informações, dentre elas: 
            \begin{itemize}
                \item Quantas maquinas existem;
                \item Quantos \textit{Jobs} existem;
                \item Quantas operações cada \textit{Job} possui;
                \item Em qual maquina cada operação pode ser executada;
                \item Quanto tempo cada operação leva para ser executada em sua respectiva maquina;
            \end{itemize}
        %% Fim do [Representações] %%


        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.3 ::: JSP
        %% 1.1.3.1 ::: Representações
        %% 1.1.3.1.1
        \subsubsubsection{Instancia de um Problema}
            Na figuraX é possível ver um exemplo de uma instância de problema de \textit{Job Shop}. A onde existem duas maquinas $(M1, $ e $M2)$, dois \textit{jobs} $(J1, $ e $J2)$ e que cada \textit{job} possui duas operações $(Oj,1 $ e $Oj,2)$.\newline
            Sendo assim:\newline
            A $O1,1$ na máquina $M2$ tem o tempo de execução 9.\newline 
            A $O1,2$ na máquina $M1$ tem o tempo de execução 5.\newline
            A $O2,1$ na máquina $M1$ tem o tempo de execução 1. \newline
            A $O2,2$ na máquina $M2$ tem o tempo de execução 7. \newline

            \textit{\textbf{Inserir a figuraX aqui}}\newline
        %% Fim do [Instancia de um Problema] %%

     %%
    %% Fim do [JSP] %%


    %% 1 ::: Introdução
    %% 1.1 ::: Problemas de Agendamento
    %% 1.1.4
    \subsection{Problema de Job Shop Flexível — FJSP}
        %% Interlúdio do [FJSP]%%
            O \textit{Flexible Job Shop} é uma extensão do problema de \textit{Job Shop} em que é permitido que uma operação seja executada em mais de uma máquina. Então além de definir a ordem e a maquina de execução de cada \textit{job} também é preciso definir o agendamento das operações.\newline 
            De um lado isso traz uma maior complexidade para o algoritmo, porém possibilita uma maior número de possíveis soluções e deixa o algoritmo mais flexível para encontrar soluções. Mas por esse aumento de fatores a considerar o \textit{Flexible Job Shop} é considerado um problema mais complexo que o \textit{Job Shop}.\newline

            Existem sub divisões no problema de \textit{FJSP}, sendo elas a \textbf{Parcial} (P-FJSP) se uma operação só pode ser processada por um certo sub conjunto de máquinas, ou \textbf{Total} (T-FJSP) caso uma operação possa ser processada por qualquer máquina.\newline

            Para o \textit{Flexible Job Shop} são aplicadas as mesmas restrições do \textit{Job Shop} com exceção da que diz um \textit{job} não pode ser processado duas vezes em uma mesma maquina.\newline
        %% Fim do Interlúdio do [FJSP]%%

        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.4 ::: FJSP
        %% 1.1.4.1
        \subsubsection{Representações}
            As representações do \textit{Flexible Job Shop} são praticamente as mesma do \textit{Job Shop} com exceção da representação do problema, devido a sua natureza flexível uma representação do \textit{Flexible Job Shop} precisa definir quanto tempo cada maquina utilizaria para processar cada operação. Porém, no caso de uma problema de \textit{Flexible Job Shop} Parcial, ou seja, em que uma operação não pode ser processada por qualquer máquina, a representação não precisa definir o tempo de processamento de todas as operações para todas as maquinas, mas somente para as máquinas que podem processar aquela operação
        %% Fim do [Representações] %%


        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.4 ::: FJSP
        %% 1.1.4.1 ::: Representações
        %% 1.1.4.1.1
        \subsubsubsection{Instancia de um Problema}
            Na TabelaX é mostrado uma instância de um problema de \textit{Flexible Job Shop} Total. Devido a sua flexibilidade a instância de problema precisa informar quanto tempo cada maquina utilizaria para executar cada operação, logo uma instância de um problema de \textit{Flexible Job Shop} é consideravelmente maior.\newline

            A representação a seguir tem um exemplo de problema com dez maquinas $(M1, M2, M3, ..., M10)$ e dez \textit{jobs} $(J1, J2, J3, ..., J10)$ e cada \textit{job} possuindo três operações $(Oj1, Oj2 e Oj3)$.\newline

            Cada índice $ji$ da Tabelax representa o tempo $Tji$ de execução de $Oji$, para cada máquina $Mk$, sendo $k = 1,... m$, onde $m$ é a quantidade de máquinas e $n$ a quantidade de jobs, ou seja, nesse exemplo $n = 10$ e $m = 10$.\newline
            Então esse problema é de tamanho 10 x 10 como visto no benchmark de \cite{Kacem2002}.\newline

            \textit{\textbf{Inserir a TabelaX aqui}}\newline
        %% Fim do [Instancia de um Problema] %%


        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.4 ::: FJSP
        %% 1.1.4.1 ::: Representações
        %% 1.1.4.1.2
        \subsubsubsection{Solução}

            Na FiguraX é possível ver um gráfico de Gantt para uma solução para o problema representado na TabelaX, sendo um problema de \cite{Kacem2002} de tamanho 10 x 10. Nessa solução é possível se observar:
            \begin{itemize}
                \item A máquina $M1$ executa as operações $[(O1,1), (O7,1), (O2,1)]$.
                \item Cada \textit{job} utiliza no mínimo duas máquinas para ser executado, por exemplo: o $J1$ é executado nas máquinas $M1 , M3, M4$.
                \item O \textit{fitness} dessa solução é 7.
            \end{itemize}

            ...\newline

            \textit{\textbf{Inserir a TabelaX aqui}}\newline
        %% Fim do [Solução] %%


        %% 1 ::: Introdução
        %% 1.1 ::: Problemas de Agendamento
        %% 1.1.4 ::: FJSP
        %% 1.1.4.2
        \subsubsection{Cenários de Aplicação}
            O exemplo mais claro de aplicação do problema de \textit{Flexible Job Shop} é em produção industrial e em sistemas de manufatura, o que traz muito interesse econômico para boas soluções para essa categoria de problema.\newline
            Como visto por \cite{Wari2016} nos tempos modernos onde a uma grande competição e constante melhorias tecnológicas, a organização e otimização desses processos industriais se torna um gargalo a ser resolvido e pode ser um fator decisório no sucesso de uma indústria.
        %% Fim do [Cenários de Aplicação] %%
        
     %%
    %% Fim do [FJSP] %%
    
 %%
%% Fim do [Problemas de Agendamento] %%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% 1 ::: Introdução
%% 1.2
\section{Soluções Existentes}
    %% Interlúdio %%
        Ao longo do tempo foram propostas, testadas, revisadas e aprimoradas diversas soluções para os problemas de agendamento, e como cada cenário de aplicação difere não é possível definir qual solução é a melhor, pois isso depende de caso a caso, contudo, durante o tempo varias soluções se destacaram como mais eficientes e adaptáveis a novas demandas, cenários e objetivos. \newline
        
        Um tipo de solução muito recorrente são as baseadas em comportamento biológico. Ao longo de milhões de anos a vida biológica no planeta terra evoluiu e se adaptou para encontrar o modo mais eficiente de resolver os diversos problemas que a natureza os impõe. Então observando esses comportamentos adaptativos, foram propostos diversos algoritmos como os algoritmos populacionais que simulam como populações, como, por exemplo, bandos de aves, enxames de abelhas ou colonias de formigas usam o comportamento de bando para solucionar um problema como o de encontrar alimento, ou fugir de predadores. Ou algoritmos que simulam as próprias regras de seleção natural para evoluir indivíduos de uma população para gerar e acumular mutações para achar um individuo mais adaptado e solucionar o problema, esses são os algoritmos genéticos e algoritmos evolutivos.
    %% Fim do Interlúdio %%


    %% 1 ::: Introdução
    %% 1.2 ::: Soluções Existentes
    \subsection{Algoritmos Evolutivos}
        Os Algoritmos Evolutivos são baseados no mecanismo de seleção natural observado na natureza. Então um individuo que tem alguma característica que o destaque tem maior chance de se reproduzir e transmitir essa característica para os seus descendentes.\newline
        A estrutura básica de um algoritmo evolutivo é:
        \begin{enumerate}
            \item Inicialização da população;
            \item Analise da qualidade de cada indivíduo;
            \item Seleção dos melhores indivíduos;
            \item Cruzamento desses indivíduos, de modo a gerar uma nova população;
            \item Repetição a partir do passo 2;
        \end{enumerate}
        Essa estrutura se repete até que seja atingido o critério de parada estabelecido pelo problema em questão.\newline
        Além da estrutura básica é possível melhorar um algoritmo evolutivo através de um aprendizado continuo, ou seja, em um ambiente em que tenha mudanças constantes um algoritmo evolutivo pode se adaptar e assim se auto melhorar sem a necessidade de uma intervenção do programador.
    %% Fim do [Alg EV] %%


    %% 1 ::: Introdução
    %% 1.2 ::: Soluções Existentes
    \subsection{Algoritmos Genéticos}
        Uma derivação dos algoritmos evolutivos são os algoritmos genéticos, utilizados para buscas e para otimizações, como nos problemas de escalonamento. Essa abordagem chama atenção por conseguir lidar com uma grande diversidade de soluções, o que a torna interessante especialmente em problemas de multi-objetivo como visto por \cite{Bagchi1999}.\newline
        
        Os algoritmos genéticos são com certeza a abordagem mais utilizada dentre os algoritmos evolutivos, o que algumas vezes podem gerar a impressão de que algoritmos genéticos e evolutivos são a mesma coisa, porém como o algoritmo genético lida com uma simulação de cromossomos isso o faz com que suas estruturas sejam muito mais dinâmicas, enquanto as técnicas de algoritmos evolutivos tem estruturas mais fixas.\newline
        Para ter essa dinamicidade os algoritmos genéticos trabalham com o conceito de mutações aleatórias, que podem ou não serem boas para o indivíduo, porém, por ser uma derivação dos algoritmos evolutivos o algoritmo genético conta também com os mecanismos de seleção e cruzamento da população, o que tende a selecionar apenas os indivíduos com mutações que são positivas do ponto de vista do objetivo estabelecido.
    %% Fim do [GA] %%


    %% 1 ::: Introdução
    %% 1.2 ::: Soluções Existentes
    \subsection{Algoritmos Populacionais}
        Outra abordagem dos algoritmos bioinspirados são os algoritmos populacionais, em que normalmente não se é utilizado técnicas de evolução do indivíduo específico, mas o foco é dado no comportamento da população.\newline
        Seus cenários de aplicação vão além dos algoritmos de otimização e também são utilizados em algoritmos de busca e em efeitos visuais, sendo amplamente utilizada em filmes. \newline
        
        Os algoritmos populacionais usam o conceito de inteligência de bando, onde indivíduos simples interagem entre si e com o ambiente e juntos convergem para uma solução.\newline
        A inteligência de bando pode ser vista em diversos lugares da natureza, como em colonias de formigas, enxames de abelhas, na forma de voo migratório de aves, na forma de casa de aves predatórias como águias, na organização de cardumes de peixes.\newline

        O que torna essa abordagem interessante é a sua característica decentralizada e de auto organização, o que a torna mais extensível e adaptável a cenários distribuídos. Um exemplo da utilização de algoritmos populacionais é na auto organização de drones e robôs, definidas como \textit{Swarm Robotics}. Fazendo assim com que por se algum robô tiver um defeito isso não afete a organização do grupo. \newline
        Dentre os principais algoritmos populacionais estão:
        \begin{itemize}
            \item Optimização por Colonia de Formigas (\textit{Ant Colony Optimization}) 
            \item Difusão Estocástica de Busca (\textit{Stochastic Diffusion Search})
            \item Optimização por Enxame de Partículas (\textit{Particle Swarm Optimization})
        \end{itemize}
        
        Todos eles se baseiam em como a população de indivíduos encontram juntos um objetivo. Nesse trabalho é utilizado o algoritmo de Optimização por Enxame de Partículas. 
    %% Fim do [Algoritmos Populacionais] %%

 %%
%% Fim do [Soluções Existentes] %%

%% 1 ::: Introdução
%% 1.3
\section{Particle Swarm Optimization — PSO}
    %% Interlúdio %%
        O algoritmo de Optimização por Enxame de Partículas ou PSO da sigla em inglês para (\textit{Particle Swarm Optimization}) é um algoritmo baseado nas teorias de inteligência de enxame. E diferentemente de outros algoritmos baseados em populações, como o \textit{Ant Colony Optimization} o \textit{Particle Swarm Optimization} é baseado em uma população genérica de indivíduos, embora sejam normalmente ilustrados como uma população de aves.
    %% Fim do [Interlúdio] %%


    %% 1 ::: Introdução
    %% 1.3 ::: PSO
    %% 1.3.1
    \subsection{Historia}
        O algoritmo \textit{Particle Swarm Optimization} for proposto por \cite{Kennedy1995} e desde então tem se mostrado muito promissor para a solução de diversos problemas de optimização. Por ser um algoritmo bem simples e flexível, ao longo do tempo já foram propostas varias variações para ele. \newline
        
        Porém, o \textit{Particle Swarm Optimization} já foi alvo de várias discussões na área, pois alguns autores discordam de ele ser classificada como parte dos algoritmos evolutivos, pois embora haja variações que sim, o \textit{Particle Swarm Optimization} original não implementa mecanismos de seleção, cruzamento e mutação, critérios base para os algoritmos evolutivos. \newline
        Atualmente o \textit{Particle Swarm Optimization} é classificado como parte da família dos algoritmos de \textit{Swarm Intelligence}.
    %% Fim do [Historia] %%


    %% 1 ::: Introdução
    %% 1.3 ::: PSO
    %% 1.3.2
    \subsection{Definição}
        A definição básica do algoritmo \textit{Particle Swarm Optimization} é uma população de partículas (também chamadas indivíduos), em que cada partícula tem uma velocidade e uma direção, além das informações da sua posição, qual é a qualidade de sua posição, qual foi a melhor posição na, qual ela já esteve, e acesso a um conhecimento compartilhado entre todos os indivíduos com a melhor posição em que qualquer um deles já esteve. E assim a cada rodada as partículas se movimentam com base na sua melhor posição e na melhor posição geral, e assim a cada rodada a população converge para uma solução ótima.\newline
        
        As variáveis mais importantes do PSO são justamente as melhores posições, sendo a local normalmente chamada de $pBest$ e a geral normalmente chamada de $gBest$. Elas vão ser utilizadas para obter uma média que será a nova posição da partícula. Porém, existem resistências para que a partícula mude de direção, isso acontece por meio da inércia normalmente representada por $w$ que representa a força que tende a fazer a partícula seguir a direção onde ela já está se movendo. Essa força de inércia cresce conforme o valor de velocidade da partícula, normalmente representada por $v$, ou seja, partículas com uma maior velocidade ($v$) tendem a tem uma maior inércia ($w$).\newline
        
        No pseudocodigoX é possível uma representação de um algoritmo PSO básico, esse algoritmo tem como base a formulação de \cite{martinez2009}.
        
        \textit{inserir o pseudocodigoX aqui}

        Na definição base do algoritmo não existe uma especificação de uma fórmula para o cálculo da movimentação da partícula. Porém, na formulaX é possível ver uma representação de uma fórmula base para o cálculo de uma nova posição para a partícula.

        \textit{inserir a formulaX aqui}

     %%
    %% Fim do [Definição] %%
    

    %% 1 ::: Introdução
    %% 1.3 ::: PSO
    %% 1.3.4
    \subsection{Problemas}
        Alguns cuidados devem ser tomados para a implementação do \textit{Particle Swarm Optimization} pois o algoritmo se mal configurado através dos parâmetros de velocidade, inercia e tamanho da população, tende a convergir prematuramente para uma solução não ótima, esse problema é normalmente chamado "Convergência Prematura".\newline
        
        Algumas medidas podem ser tomadas para diminuir essa possibilidade de convergência Prematura, como valores dinâmicos de inércia e uma ponderação nos valores de importância de $pBest$ e $gBest$.
    %% Fim do [Problemas] %%


    %% 1 ::: Introdução
    %% 1.3 ::: PSO
    %% 1.3.5
    \subsection{Melhorias}
        %% Interludio %%
            Algumas técnicas podem ser usadas para melhorar o desempenho do PSO em cada cenário de aplicação. Porém, o efeito dessas abordagens varia de acordo com qual problema esta sendo resolvido e dos recursos e limitações de processamento e memoria do ambiente de processamento do algoritmo.
        %% Fim do [Interludio] %%

        \subsubsection{Multithreading}
            Uma abordagem com bons resultados é o processamento distribuído do cálculo de cada partícula como visto por \cite{Thongkrairat2019} e \cite{Kim2011}. Essa paralelização é possível graças a natureza distribuída dos algoritmos populacionais. No caso do \textit{Particle Swarm Optimization} o único fator a se considerar para uma implementação distribuída é a atualização da variavel $gBest$.\newline
            
            Um cenário que tira um bom proveito dessa abordagem são os de robôs e drones.            
        %% Fim do [Multitheading] %%

        \subsubsection{Hibridização}
            Outra melhoria que tem dado bons resultados é a hibridização de PSO com outros algoritmos, como algoritmos genéticos como demostrado por \cite{carvalho2014}, ou com outros algoritmos evolutivos.\newline
            Essas hibridizações com algoritmos evolutivos são tão boas pela característica básica do PSO de não ter componentes evolutivos em seus indivíduos, então uma adição de componentes evolutivos não atrapalha nenhum ponto do PSO. \newline
            
            Esses componentes evolutivos normalmente trabalham nos valores de inércia e de velocidade, criando partículas mais teimosas ou com uma tendência maior a fugir da convergência do grupo, o que pode ajudar a escapar de mínimos locais, evitando assim a convergência prematura.\newline
            
            Um cenário que tem um bom proveito da hibridização evolutiva do PSO são os cenários com multi-objetivo, pois os componentes de mutação de algoritmos genéticos trazem uma maior diversidade para os indivíduos da população, trazendo assim uma maior gama de exploração no espaço de soluções.
        %% Fim do [Hibridização] %%

        \subsubsection{Dinamicidade}
            Outra abordagem promissora é a implementação de componentes dinâmicos na população, ou seja, que possam mudar suas características como velocidade e inercia de maneira dinâmica, por exemplo, se uma partícula perceber que esta longe do $gBest$ e está se movendo pouco ela pode reconhecer que possivelmente esta em um mínimo local e diminuir seu valor de inércia afim ou o fator de importância do seu $pBest$.\newline
            
            Essa abordagem pode ser feita de maneira constante nas partículas, fazendo elas se atualizarem em tempo real.
        %% Fim do [Dinamicidade] %%
     %
    %% Fim do [Melhorias] %%

 %
%% Fim do [PSO] %%

